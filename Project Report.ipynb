{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cc3068-19df-4789-8003-6c93f32b24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note using suppress to reduce constant red warning boxes\n",
    "#TODO FABIO check if packages must be installed for reproducibility\n",
    "suppressPackageStartupMessages({\n",
    "    suppressWarnings({\n",
    "        library(tidyverse)\n",
    "        library(repr)\n",
    "        library(tidymodels)\n",
    "        library(tidyr)\n",
    "        library(dplyr)\n",
    "        library(workflowsets)\n",
    "    })\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6835e69-f7f5-464f-82f6-30822b64581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size and general style set up\n",
    "options(repr.plot.width = 6, repr.plot.height = 4, repr.matrix.max.rows = 7,readr.show_col_types = FALSE)\n",
    "\n",
    "# Load Data\n",
    "player_data <- read_csv(\"https://raw.githubusercontent.com/FabianoGLentini/player-subscription-ml/refs/heads/main/data/players.csv\")\n",
    "# TODO may not need session data\n",
    "# session_data <- read_csv(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba86744-400f-4dcd-8a8e-d40a6c04c3ba",
   "metadata": {},
   "source": [
    "# Data Science Project: Project Final Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79d611-bb1a-417d-8151-a47a3f18bc4c",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9c28a-520a-4840-9971-940358c941f3",
   "metadata": {},
   "source": [
    "## Methods & Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f840b84-52a5-4173-b394-2ff25a57d503",
   "metadata": {},
   "source": [
    "### Set up and intro to data: \"TODO should rename later.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1048e5-80b2-4816-a210-d109eb6b6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle data\n",
    "player_df <- player_data |> # TODO must consider reworking a joining of some labels in gender etc due to low representaions\n",
    "            select( subscribe, gender, played_hours, experience, Age) |>\n",
    "            drop_na() |>\n",
    "            mutate(\n",
    "                subscribe = as_factor(subscribe),  # lgl -> fct for analysis and modeling\n",
    "                gender = as_factor(gender),        # chr -> fct for analysis and modeling\n",
    "                experience = as_factor(experience) # chr -> fct for analysis and modeling\n",
    "            ) \n",
    " # Removed row with NA values, as it may distort the model      \n",
    "\n",
    "# TODO FABIO check if player_hours should adjust to use a binary outcome, \n",
    "# either played or didn't play at all, or if any of the predictor should be removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4497e-57ac-4d04-b510-4c3c78cc7d3c",
   "metadata": {},
   "source": [
    "### Training and Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f28c8d1-6474-43c7-8363-29f7c2307352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>subscribe</th><th scope=col>gender</th><th scope=col>played_hours</th><th scope=col>experience</th><th scope=col>Age</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>TRUE </td><td>Male  </td><td>30.3</td><td>Pro    </td><td> 9</td></tr>\n",
       "\t<tr><td>TRUE </td><td>Male  </td><td> 3.8</td><td>Veteran</td><td>17</td></tr>\n",
       "\t<tr><td>FALSE</td><td>Male  </td><td> 0.0</td><td>Veteran</td><td>17</td></tr>\n",
       "\t<tr><td>TRUE </td><td>Female</td><td> 0.7</td><td>Amateur</td><td>21</td></tr>\n",
       "\t<tr><td>TRUE </td><td>Male  </td><td> 0.1</td><td>Regular</td><td>21</td></tr>\n",
       "\t<tr><td>TRUE </td><td>Female</td><td> 0.0</td><td>Amateur</td><td>17</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " subscribe & gender & played\\_hours & experience & Age\\\\\n",
       " <fct> & <fct> & <dbl> & <fct> & <dbl>\\\\\n",
       "\\hline\n",
       "\t TRUE  & Male   & 30.3 & Pro     &  9\\\\\n",
       "\t TRUE  & Male   &  3.8 & Veteran & 17\\\\\n",
       "\t FALSE & Male   &  0.0 & Veteran & 17\\\\\n",
       "\t TRUE  & Female &  0.7 & Amateur & 21\\\\\n",
       "\t TRUE  & Male   &  0.1 & Regular & 21\\\\\n",
       "\t TRUE  & Female &  0.0 & Amateur & 17\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 5\n",
       "\n",
       "| subscribe &lt;fct&gt; | gender &lt;fct&gt; | played_hours &lt;dbl&gt; | experience &lt;fct&gt; | Age &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| TRUE  | Male   | 30.3 | Pro     |  9 |\n",
       "| TRUE  | Male   |  3.8 | Veteran | 17 |\n",
       "| FALSE | Male   |  0.0 | Veteran | 17 |\n",
       "| TRUE  | Female |  0.7 | Amateur | 21 |\n",
       "| TRUE  | Male   |  0.1 | Regular | 21 |\n",
       "| TRUE  | Female |  0.0 | Amateur | 17 |\n",
       "\n"
      ],
      "text/plain": [
       "  subscribe gender played_hours experience Age\n",
       "1 TRUE      Male   30.3         Pro         9 \n",
       "2 TRUE      Male    3.8         Veteran    17 \n",
       "3 FALSE     Male    0.0         Veteran    17 \n",
       "4 TRUE      Female  0.7         Amateur    21 \n",
       "5 TRUE      Male    0.1         Regular    21 \n",
       "6 TRUE      Female  0.0         Amateur    17 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(player_df) # TODO DELETE tmp  for set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2132631e-e072-43ae-a996-beb8fecd0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2025) # Don't change\n",
    "# Prep for modelling\n",
    "ply_df <- select(player_df, Age, subscribe, gender, played_hours)  # Exclude row_id & experience for modeling purposes\n",
    "\n",
    "# Split step\n",
    "player_split <- initial_split(ply_df, prop = 0.75, strata = subscribe) \n",
    "player_train <- training(player_split)\n",
    "player_test <- testing(player_split)\n",
    "\n",
    "# TODO FABIO CHECK boostraps() and if it would benefit our model with our small set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66a48e3b-7c2c-453c-b128-4af77f2b9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO FABIO write up split/scale/recipe step reasoning\n",
    "# 'initial split' Use Strata sub to balance the outcome for the bool prediction to avoid \n",
    "# imbalance in our test and train data split\n",
    "\n",
    "# ... why use 75 25 split instead of 70/30 etc?\n",
    "\n",
    "# ~ maybe explain why start with all predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05623ab7-5eec-4ae6-bff4-7b461e5d99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO FABIO ... search refractor options to reduce code clutter\n",
    "\n",
    "# Recipes:\n",
    "# Scale/Recipe\n",
    "\n",
    "# Note: A = Age, G = gender and H = played_hours\n",
    "# Recipe 01:\n",
    "# Age + gender + played_hours\n",
    "rc_AGH <- recipe(subscribe ~ Age + gender + played_hours, data = player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "# # Recipe 02:\n",
    "# Age + played_hours\n",
    "rc_AH <- recipe(subscribe ~ Age + played_hours, player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Recipe 03:\n",
    "# Age + gender \n",
    "rc_AG <- recipe(subscribe ~ Age + gender, player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Recipe 04:\n",
    "# gender + played_hours\n",
    "rc_GH <- recipe(subscribe ~ gender + played_hours, player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Recipe 05:\n",
    "# Age\n",
    "rc_A <- recipe(subscribe ~ Age, player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Recipe 06:\n",
    "# gender\n",
    "rc_G <- recipe(subscribe ~ gender, player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "\n",
    "# Recipe 07:\n",
    "# played_hours\n",
    "rc_H <- recipe(subscribe ~ played_hours, player_train) |>\n",
    "            step_dummy(all_nominal_predictors()) |>\n",
    "            step_zv(all_predictors()) |> # Used to remove zero-variance variable after wrangling, gender_Other category had no rows associated to i \n",
    "            step_normalize(all_numeric_predictors())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1a1557-da2a-4619-9540-e21ade5729ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO FABIO breackdown hypothesis for each recipe variation ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09550a8-d9b2-43e6-ad32-a5f30893ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec set up\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "            set_engine(\"kknn\") |>\n",
    "            set_mode(\"classification\")\n",
    "\n",
    "#TODO FABIO ... search refractor options to reduce code clutter\n",
    "# Check mean and standard error through collect_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c10cb7-616e-4165-a4b1-3810137e5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FABIO ~ write up spec use and impl of vfold..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "432c082c-0384-4375-9bcc-a16ccf2544a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FABIO confirm that not having set.seed here is fine as long as set.seed above code cell goes first\n",
    "# K-fold cross-validation\n",
    "kfolds <- vfold_cv(player_train, v = 5, strata = subscribe)\n",
    "k_grid = tibble(neighbors = seq(from = 1, to = 10, by = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5110aa83-e105-47bb-ae5d-ebb9db207d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO FABIO write reasonin + graph to show fold outcome\n",
    "#Note the reason of using 10 10-fold is due to the small size data,\n",
    "#hence it will improve the estimate and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93f32197-2dcc-484f-a7ec-2bc798585f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A workflow set/tibble: 7 × 4\u001b[39m\n",
      "  wflow_id                  info             option    result   \n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<list>\u001b[39m\u001b[23m   \n",
      "\u001b[90m1\u001b[39m recipe_1_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n",
      "\u001b[90m2\u001b[39m recipe_2_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n",
      "\u001b[90m3\u001b[39m recipe_3_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n",
      "\u001b[90m4\u001b[39m recipe_4_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n",
      "\u001b[90m5\u001b[39m recipe_5_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n",
      "\u001b[90m6\u001b[39m recipe_6_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n",
      "\u001b[90m7\u001b[39m recipe_7_nearest_neighbor \u001b[90m<tibble [1 × 4]>\u001b[39m \u001b[90m<opts[3]>\u001b[39m \u001b[90m<tune[+]>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "#TODO FABIO ... search refractor options to reduce code clutter/redundancy \n",
    "# Simplifying multi model testing: https://www.youtube.com/watch?v=YZqbOATpjM4&t=139s\n",
    "# Workflow Step\n",
    "workflow_set <- workflow_set(\n",
    "    preproc = list(\n",
    "        rc_AGH,\n",
    "        rc_AH,\n",
    "        rc_AG,\n",
    "        rc_GH,\n",
    "        rc_A,\n",
    "        rc_G,\n",
    "        rc_H\n",
    "    ),\n",
    "    models = list(player_spec),\n",
    ")\n",
    "\n",
    "set.seed(22)\n",
    "\n",
    "ply_set_res <- workflow_map(\n",
    "    workflow_set,\n",
    "    \"tune_grid\",\n",
    "    resamples = kfolds,\n",
    "    grid = k_grid,\n",
    "    metrics = metric_set(accuracy)\n",
    ")\n",
    "print(ply_set_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887cbf5-2fdf-4774-addf-474743338b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO FABIO write workflow step use case/what it functionally is doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7a7b0-c16f-4ed0-ae35-6ed861b6aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Step\n",
    "knn_res <- player_wf_All |>\n",
    "        tune_grid(\n",
    "            resamples = kfolds,\n",
    "            grid = k_grid\n",
    "        ) |>\n",
    "        collect_metrics()\n",
    "\n",
    "accuracies <- knn_res |>\n",
    "            filter(.metric == \"accuracy\")\n",
    "\n",
    "cross_val_plot <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "                  geom_point() +\n",
    "                  geom_line() +\n",
    "                  labs(x = 'Neighbors', y = 'Accuracy Estimate')\n",
    "\n",
    "\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c79929-d0d4-4742-bf38-bfa82f78bd9e",
   "metadata": {},
   "source": [
    "### Player Type Exploration: \"TODO may need renaming\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b83e19-66be-493e-9b25-70c2585e8c13",
   "metadata": {},
   "source": [
    "## Discussion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990329f-6cb6-4318-a8be-503437ef2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref \n",
    "# Data Science programming techniques and approaches:\n",
    "# Clustering prediction: https://www.youtube.com/watch?v=z57i2GVcdww\n",
    "# Simplifying multi model set up + testing: https://www.youtube.com/watch?v=YZqbOATpjM4\n",
    "# Tuning and comparing models using Workflowse: https://workflowsets.tidymodels.org/articles/tuning-and-comparing-models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef75d510-84b9-43bc-bb8e-241e6dc85b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table style=\"width: 100%;\"><tr><td>workflow_map {workflowsets}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2 id='workflow_map'>Process a series of workflows</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>workflow_map()</code> will execute the same function across the workflows in the\n",
       "set. The various <code style=\"white-space: pre;\">&#8288;tune_*()&#8288;</code> functions can be used as well as\n",
       "<code>tune::fit_resamples()</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre><code class='language-R'>workflow_map(\n",
       "  object,\n",
       "  fn = \"tune_grid\",\n",
       "  verbose = FALSE,\n",
       "  seed = sample.int(10^4, 1),\n",
       "  ...\n",
       ")\n",
       "</code></pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table>\n",
       "<tr><td><code id=\"workflow_map_:_object\">object</code></td>\n",
       "<td>\n",
       "<p>A workflow set.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"workflow_map_:_fn\">fn</code></td>\n",
       "<td>\n",
       "<p>The name of the function to run, as a character. Acceptable values are:\n",
       "&quot;tune_grid&quot;,\n",
       "&quot;tune_bayes&quot;,\n",
       "&quot;fit_resamples&quot;,\n",
       "&quot;tune_race_anova&quot;,\n",
       "&quot;tune_race_win_loss&quot;, or\n",
       "&quot;tune_sim_anneal&quot;. Note that users need not\n",
       "provide the namespace or parentheses in this argument,\n",
       "e.g. provide <code>\"tune_grid\"</code> rather than <code>\"tune::tune_grid\"</code> or <code>\"tune_grid()\"</code>.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"workflow_map_:_verbose\">verbose</code></td>\n",
       "<td>\n",
       "<p>A logical for logging progress.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"workflow_map_:_seed\">seed</code></td>\n",
       "<td>\n",
       "<p>A single integer that is set prior to each function execution.</p>\n",
       "</td></tr>\n",
       "<tr><td><code id=\"workflow_map_:_...\">...</code></td>\n",
       "<td>\n",
       "<p>Options to pass to the modeling function. See details below.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>When passing options, anything passed in the <code>...</code> will be combined with any\n",
       "values in the <code>option</code> column. The values in <code>...</code> will override that\n",
       "column's values and the new options are added to the <code>options</code> column.\n",
       "</p>\n",
       "<p>Any failures in execution result in the corresponding row of <code>results</code> to\n",
       "contain a <code>try-error</code> object.\n",
       "</p>\n",
       "<p>In cases where a model has no tuning parameters is mapped to one of the\n",
       "tuning functions, <code>tune::fit_resamples()</code> will be used instead and a\n",
       "warning is issued if <code>verbose = TRUE</code>.\n",
       "</p>\n",
       "<p>If a workflow requires packages that are not installed, a message is printed\n",
       "and <code>workflow_map()</code> continues with the next workflow (if any).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>An updated workflow set. The <code>option</code> column will be updated with\n",
       "any options for the <code>tune</code> package functions given to <code>workflow_map()</code>. Also,\n",
       "the results will be added to the <code>result</code> column. If the computations for a\n",
       "workflow fail, a <code>try-catch</code> object will be saved in place of the results\n",
       "(without stopping execution).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>\n",
       "and <code>chi_features_set</code>, and associated sets of model fits\n",
       "<code>two_class_res</code> and <code>chi_features_res</code>.\n",
       "</p>\n",
       "<p>The <code style=\"white-space: pre;\">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem\n",
       "using the <code>two_class_dat</code> data from the modeldata package. The six\n",
       "models utilize either a bare formula or a basic recipe utilizing\n",
       "<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,\n",
       "logistic regression, or MARS model specification. See <code>?two_class_set</code>\n",
       "for source code.\n",
       "</p>\n",
       "<p>The <code style=\"white-space: pre;\">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the\n",
       "<code>Chicago</code> data from the modeldata package. Each of the three models\n",
       "utilize a linear regression model specification, with three different\n",
       "recipes of varying complexity. The objects are meant to approximate the\n",
       "sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See\n",
       "<code>?chi_features_set</code> for source code.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>workflow_set()</code>, <code>as_workflow_set()</code>, <code>extract_workflow_set_result()</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre><code class='language-R'>\n",
       "library(workflowsets)\n",
       "library(workflows)\n",
       "library(modeldata)\n",
       "library(recipes)\n",
       "library(parsnip)\n",
       "library(dplyr)\n",
       "library(rsample)\n",
       "library(tune)\n",
       "library(yardstick)\n",
       "library(dials)\n",
       "\n",
       "# An example of processed results\n",
       "chi_features_res\n",
       "\n",
       "# Recreating them:\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "data(Chicago)\n",
       "Chicago &lt;- Chicago[1:1195,]\n",
       "\n",
       "time_val_split &lt;-\n",
       "   sliding_period(\n",
       "      Chicago,\n",
       "      date,\n",
       "      \"month\",\n",
       "      lookback = 38,\n",
       "      assess_stop = 1\n",
       "   )\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "base_recipe &lt;-\n",
       "   recipe(ridership ~ ., data = Chicago) %&gt;%\n",
       "   # create date features\n",
       "   step_date(date) %&gt;%\n",
       "   step_holiday(date) %&gt;%\n",
       "   # remove date from the list of predictors\n",
       "   update_role(date, new_role = \"id\") %&gt;%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %&gt;%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors()) %&gt;%\n",
       "   step_normalize(all_predictors())\n",
       "\n",
       "date_only &lt;-\n",
       "   recipe(ridership ~ ., data = Chicago) %&gt;%\n",
       "   # create date features\n",
       "   step_date(date) %&gt;%\n",
       "   update_role(date, new_role = \"id\") %&gt;%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %&gt;%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors())\n",
       "\n",
       "date_and_holidays &lt;-\n",
       "   recipe(ridership ~ ., data = Chicago) %&gt;%\n",
       "   # create date features\n",
       "   step_date(date) %&gt;%\n",
       "   step_holiday(date) %&gt;%\n",
       "   # remove date from the list of predictors\n",
       "   update_role(date, new_role = \"id\") %&gt;%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %&gt;%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors())\n",
       "\n",
       "date_and_holidays_and_pca &lt;-\n",
       "   recipe(ridership ~ ., data = Chicago) %&gt;%\n",
       "   # create date features\n",
       "   step_date(date) %&gt;%\n",
       "   step_holiday(date) %&gt;%\n",
       "   # remove date from the list of predictors\n",
       "   update_role(date, new_role = \"id\") %&gt;%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %&gt;%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors()) %&gt;%\n",
       "   step_pca(!!stations, num_comp = tune())\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "lm_spec &lt;- linear_reg() %&gt;% set_engine(\"lm\")\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "pca_param &lt;-\n",
       "   parameters(num_comp()) %&gt;%\n",
       "   update(num_comp = num_comp(c(0, 20)))\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "chi_features_set &lt;-\n",
       "   workflow_set(\n",
       "      preproc = list(date = date_only,\n",
       "                     plus_holidays = date_and_holidays,\n",
       "                     plus_pca = date_and_holidays_and_pca),\n",
       "      models = list(lm = lm_spec),\n",
       "      cross = TRUE\n",
       "   )\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "chi_features_res_new &lt;-\n",
       "   chi_features_set %&gt;%\n",
       "   option_add(param_info = pca_param, id = \"plus_pca_lm\") %&gt;%\n",
       "   workflow_map(resamples = time_val_split, grid = 21, seed = 1, verbose = TRUE)\n",
       "\n",
       "chi_features_res_new\n",
       "\n",
       "</code></pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>workflowsets</em> version 1.0.1 ]</div>\n",
       "</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{workflow\\_map}{Process a series of workflows}{workflow.Rul.map}\n",
       "%\n",
       "\\begin{Description}\n",
       "\\code{workflow\\_map()} will execute the same function across the workflows in the\n",
       "set. The various \\AsIs{\\texttt{tune\\_*()}} functions can be used as well as\n",
       "\\code{\\LinkA{tune::fit\\_resamples()}{tune::fit.Rul.resamples()}}.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "workflow_map(\n",
       "  object,\n",
       "  fn = \"tune_grid\",\n",
       "  verbose = FALSE,\n",
       "  seed = sample.int(10^4, 1),\n",
       "  ...\n",
       ")\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{object}] A workflow set.\n",
       "\n",
       "\\item[\\code{fn}] The name of the function to run, as a character. Acceptable values are:\n",
       "\\LinkA{\"tune\\_grid\"}{\"tune.Rul.grid\"},\n",
       "\\LinkA{\"tune\\_bayes\"}{\"tune.Rul.bayes\"},\n",
       "\\LinkA{\"fit\\_resamples\"}{\"fit.Rul.resamples\"},\n",
       "\\LinkA{\"tune\\_race\\_anova\"}{\"tune.Rul.race.Rul.anova\"},\n",
       "\\LinkA{\"tune\\_race\\_win\\_loss\"}{\"tune.Rul.race.Rul.win.Rul.loss\"}, or\n",
       "\\LinkA{\"tune\\_sim\\_anneal\"}{\"tune.Rul.sim.Rul.anneal\"}. Note that users need not\n",
       "provide the namespace or parentheses in this argument,\n",
       "e.g. provide \\code{\"tune\\_grid\"} rather than \\code{\"tune::tune\\_grid\"} or \\code{\"tune\\_grid()\"}.\n",
       "\n",
       "\\item[\\code{verbose}] A logical for logging progress.\n",
       "\n",
       "\\item[\\code{seed}] A single integer that is set prior to each function execution.\n",
       "\n",
       "\\item[\\code{...}] Options to pass to the modeling function. See details below.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\n",
       "When passing options, anything passed in the \\code{...} will be combined with any\n",
       "values in the \\code{option} column. The values in \\code{...} will override that\n",
       "column's values and the new options are added to the \\code{options} column.\n",
       "\n",
       "Any failures in execution result in the corresponding row of \\code{results} to\n",
       "contain a \\code{try-error} object.\n",
       "\n",
       "In cases where a model has no tuning parameters is mapped to one of the\n",
       "tuning functions, \\code{\\LinkA{tune::fit\\_resamples()}{tune::fit.Rul.resamples()}} will be used instead and a\n",
       "warning is issued if \\code{verbose = TRUE}.\n",
       "\n",
       "If a workflow requires packages that are not installed, a message is printed\n",
       "and \\code{workflow\\_map()} continues with the next workflow (if any).\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "An updated workflow set. The \\code{option} column will be updated with\n",
       "any options for the \\code{tune} package functions given to \\code{workflow\\_map()}. Also,\n",
       "the results will be added to the \\code{result} column. If the computations for a\n",
       "workflow fail, a \\code{try-catch} object will be saved in place of the results\n",
       "(without stopping execution).\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\n",
       "The package supplies two pre-generated workflow sets, \\code{two\\_class\\_set}\n",
       "and \\code{chi\\_features\\_set}, and associated sets of model fits\n",
       "\\code{two\\_class\\_res} and \\code{chi\\_features\\_res}.\n",
       "\n",
       "The \\AsIs{\\texttt{two\\_class\\_*}} objects are based on a binary classification problem\n",
       "using the \\code{two\\_class\\_dat} data from the modeldata package. The six\n",
       "models utilize either a bare formula or a basic recipe utilizing\n",
       "\\code{recipes::step\\_YeoJohnson()} as a preprocessor, and a decision tree,\n",
       "logistic regression, or MARS model specification. See \\code{?two\\_class\\_set}\n",
       "for source code.\n",
       "\n",
       "The \\AsIs{\\texttt{chi\\_features\\_*}} objects are based on a regression problem using the\n",
       "\\code{Chicago} data from the modeldata package. Each of the three models\n",
       "utilize a linear regression model specification, with three different\n",
       "recipes of varying complexity. The objects are meant to approximate the\n",
       "sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See\n",
       "\\code{?chi\\_features\\_set} for source code.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{SeeAlso}\n",
       "\\code{\\LinkA{workflow\\_set()}{workflow.Rul.set}}, \\code{\\LinkA{as\\_workflow\\_set()}{as.Rul.workflow.Rul.set}}, \\code{\\LinkA{extract\\_workflow\\_set\\_result()}{extract.Rul.workflow.Rul.set.Rul.result}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "library(workflowsets)\n",
       "library(workflows)\n",
       "library(modeldata)\n",
       "library(recipes)\n",
       "library(parsnip)\n",
       "library(dplyr)\n",
       "library(rsample)\n",
       "library(tune)\n",
       "library(yardstick)\n",
       "library(dials)\n",
       "\n",
       "# An example of processed results\n",
       "chi_features_res\n",
       "\n",
       "# Recreating them:\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "data(Chicago)\n",
       "Chicago <- Chicago[1:1195,]\n",
       "\n",
       "time_val_split <-\n",
       "   sliding_period(\n",
       "      Chicago,\n",
       "      date,\n",
       "      \"month\",\n",
       "      lookback = 38,\n",
       "      assess_stop = 1\n",
       "   )\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "base_recipe <-\n",
       "   recipe(ridership ~ ., data = Chicago) %>%\n",
       "   # create date features\n",
       "   step_date(date) %>%\n",
       "   step_holiday(date) %>%\n",
       "   # remove date from the list of predictors\n",
       "   update_role(date, new_role = \"id\") %>%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %>%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors()) %>%\n",
       "   step_normalize(all_predictors())\n",
       "\n",
       "date_only <-\n",
       "   recipe(ridership ~ ., data = Chicago) %>%\n",
       "   # create date features\n",
       "   step_date(date) %>%\n",
       "   update_role(date, new_role = \"id\") %>%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %>%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors())\n",
       "\n",
       "date_and_holidays <-\n",
       "   recipe(ridership ~ ., data = Chicago) %>%\n",
       "   # create date features\n",
       "   step_date(date) %>%\n",
       "   step_holiday(date) %>%\n",
       "   # remove date from the list of predictors\n",
       "   update_role(date, new_role = \"id\") %>%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %>%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors())\n",
       "\n",
       "date_and_holidays_and_pca <-\n",
       "   recipe(ridership ~ ., data = Chicago) %>%\n",
       "   # create date features\n",
       "   step_date(date) %>%\n",
       "   step_holiday(date) %>%\n",
       "   # remove date from the list of predictors\n",
       "   update_role(date, new_role = \"id\") %>%\n",
       "   # create dummy variables from factor columns\n",
       "   step_dummy(all_nominal()) %>%\n",
       "   # remove any columns with a single unique value\n",
       "   step_zv(all_predictors()) %>%\n",
       "   step_pca(!!stations, num_comp = tune())\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "lm_spec <- linear_reg() %>% set_engine(\"lm\")\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "pca_param <-\n",
       "   parameters(num_comp()) %>%\n",
       "   update(num_comp = num_comp(c(0, 20)))\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "chi_features_set <-\n",
       "   workflow_set(\n",
       "      preproc = list(date = date_only,\n",
       "                     plus_holidays = date_and_holidays,\n",
       "                     plus_pca = date_and_holidays_and_pca),\n",
       "      models = list(lm = lm_spec),\n",
       "      cross = TRUE\n",
       "   )\n",
       "\n",
       "# ---------------------------------------------------------------------------\n",
       "\n",
       "chi_features_res_new <-\n",
       "   chi_features_set %>%\n",
       "   option_add(param_info = pca_param, id = \"plus_pca_lm\") %>%\n",
       "   workflow_map(resamples = time_val_split, grid = 21, seed = 1, verbose = TRUE)\n",
       "\n",
       "chi_features_res_new\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "workflow_map           package:workflowsets            R Documentation\n",
       "\n",
       "_\bP_\br_\bo_\bc_\be_\bs_\bs _\ba _\bs_\be_\br_\bi_\be_\bs _\bo_\bf _\bw_\bo_\br_\bk_\bf_\bl_\bo_\bw_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘workflow_map()’ will execute the same function across the\n",
       "     workflows in the set. The various tune_*() functions can be used\n",
       "     as well as ‘tune::fit_resamples()’.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     workflow_map(\n",
       "       object,\n",
       "       fn = \"tune_grid\",\n",
       "       verbose = FALSE,\n",
       "       seed = sample.int(10^4, 1),\n",
       "       ...\n",
       "     )\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "  object: A workflow set.\n",
       "\n",
       "      fn: The name of the function to run, as a character. Acceptable\n",
       "          values are: \"tune_grid\", \"tune_bayes\", \"fit_resamples\",\n",
       "          \"tune_race_anova\", \"tune_race_win_loss\", or\n",
       "          \"tune_sim_anneal\". Note that users need not provide the\n",
       "          namespace or parentheses in this argument, e.g. provide\n",
       "          ‘\"tune_grid\"’ rather than ‘\"tune::tune_grid\"’ or\n",
       "          ‘\"tune_grid()\"’.\n",
       "\n",
       " verbose: A logical for logging progress.\n",
       "\n",
       "    seed: A single integer that is set prior to each function\n",
       "          execution.\n",
       "\n",
       "     ...: Options to pass to the modeling function. See details below.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     When passing options, anything passed in the ‘...’ will be\n",
       "     combined with any values in the ‘option’ column. The values in\n",
       "     ‘...’ will override that column's values and the new options are\n",
       "     added to the ‘options’ column.\n",
       "\n",
       "     Any failures in execution result in the corresponding row of\n",
       "     ‘results’ to contain a ‘try-error’ object.\n",
       "\n",
       "     In cases where a model has no tuning parameters is mapped to one\n",
       "     of the tuning functions, ‘tune::fit_resamples()’ will be used\n",
       "     instead and a warning is issued if ‘verbose = TRUE’.\n",
       "\n",
       "     If a workflow requires packages that are not installed, a message\n",
       "     is printed and ‘workflow_map()’ continues with the next workflow\n",
       "     (if any).\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     An updated workflow set. The ‘option’ column will be updated with\n",
       "     any options for the ‘tune’ package functions given to\n",
       "     ‘workflow_map()’. Also, the results will be added to the ‘result’\n",
       "     column. If the computations for a workflow fail, a ‘try-catch’\n",
       "     object will be saved in place of the results (without stopping\n",
       "     execution).\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     The package supplies two pre-generated workflow sets,\n",
       "     ‘two_class_set’ and ‘chi_features_set’, and associated sets of\n",
       "     model fits ‘two_class_res’ and ‘chi_features_res’.\n",
       "\n",
       "     The two_class_* objects are based on a binary classification\n",
       "     problem using the ‘two_class_dat’ data from the modeldata package.\n",
       "     The six models utilize either a bare formula or a basic recipe\n",
       "     utilizing ‘recipes::step_YeoJohnson()’ as a preprocessor, and a\n",
       "     decision tree, logistic regression, or MARS model specification.\n",
       "     See ‘?two_class_set’ for source code.\n",
       "\n",
       "     The chi_features_* objects are based on a regression problem using\n",
       "     the ‘Chicago’ data from the modeldata package. Each of the three\n",
       "     models utilize a linear regression model specification, with three\n",
       "     different recipes of varying complexity. The objects are meant to\n",
       "     approximate the sequence of models built in Section 1.3 of Kuhn\n",
       "     and Johnson (2019). See ‘?chi_features_set’ for source code.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘workflow_set()’, ‘as_workflow_set()’,\n",
       "     ‘extract_workflow_set_result()’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     library(workflowsets)\n",
       "     library(workflows)\n",
       "     library(modeldata)\n",
       "     library(recipes)\n",
       "     library(parsnip)\n",
       "     library(dplyr)\n",
       "     library(rsample)\n",
       "     library(tune)\n",
       "     library(yardstick)\n",
       "     library(dials)\n",
       "     \n",
       "     # An example of processed results\n",
       "     chi_features_res\n",
       "     \n",
       "     # Recreating them:\n",
       "     \n",
       "     # ---------------------------------------------------------------------------\n",
       "     data(Chicago)\n",
       "     Chicago <- Chicago[1:1195,]\n",
       "     \n",
       "     time_val_split <-\n",
       "        sliding_period(\n",
       "           Chicago,\n",
       "           date,\n",
       "           \"month\",\n",
       "           lookback = 38,\n",
       "           assess_stop = 1\n",
       "        )\n",
       "     \n",
       "     # ---------------------------------------------------------------------------\n",
       "     \n",
       "     base_recipe <-\n",
       "        recipe(ridership ~ ., data = Chicago) %>%\n",
       "        # create date features\n",
       "        step_date(date) %>%\n",
       "        step_holiday(date) %>%\n",
       "        # remove date from the list of predictors\n",
       "        update_role(date, new_role = \"id\") %>%\n",
       "        # create dummy variables from factor columns\n",
       "        step_dummy(all_nominal()) %>%\n",
       "        # remove any columns with a single unique value\n",
       "        step_zv(all_predictors()) %>%\n",
       "        step_normalize(all_predictors())\n",
       "     \n",
       "     date_only <-\n",
       "        recipe(ridership ~ ., data = Chicago) %>%\n",
       "        # create date features\n",
       "        step_date(date) %>%\n",
       "        update_role(date, new_role = \"id\") %>%\n",
       "        # create dummy variables from factor columns\n",
       "        step_dummy(all_nominal()) %>%\n",
       "        # remove any columns with a single unique value\n",
       "        step_zv(all_predictors())\n",
       "     \n",
       "     date_and_holidays <-\n",
       "        recipe(ridership ~ ., data = Chicago) %>%\n",
       "        # create date features\n",
       "        step_date(date) %>%\n",
       "        step_holiday(date) %>%\n",
       "        # remove date from the list of predictors\n",
       "        update_role(date, new_role = \"id\") %>%\n",
       "        # create dummy variables from factor columns\n",
       "        step_dummy(all_nominal()) %>%\n",
       "        # remove any columns with a single unique value\n",
       "        step_zv(all_predictors())\n",
       "     \n",
       "     date_and_holidays_and_pca <-\n",
       "        recipe(ridership ~ ., data = Chicago) %>%\n",
       "        # create date features\n",
       "        step_date(date) %>%\n",
       "        step_holiday(date) %>%\n",
       "        # remove date from the list of predictors\n",
       "        update_role(date, new_role = \"id\") %>%\n",
       "        # create dummy variables from factor columns\n",
       "        step_dummy(all_nominal()) %>%\n",
       "        # remove any columns with a single unique value\n",
       "        step_zv(all_predictors()) %>%\n",
       "        step_pca(!!stations, num_comp = tune())\n",
       "     \n",
       "     # ---------------------------------------------------------------------------\n",
       "     \n",
       "     lm_spec <- linear_reg() %>% set_engine(\"lm\")\n",
       "     \n",
       "     # ---------------------------------------------------------------------------\n",
       "     \n",
       "     pca_param <-\n",
       "        parameters(num_comp()) %>%\n",
       "        update(num_comp = num_comp(c(0, 20)))\n",
       "     \n",
       "     # ---------------------------------------------------------------------------\n",
       "     \n",
       "     chi_features_set <-\n",
       "        workflow_set(\n",
       "           preproc = list(date = date_only,\n",
       "                          plus_holidays = date_and_holidays,\n",
       "                          plus_pca = date_and_holidays_and_pca),\n",
       "           models = list(lm = lm_spec),\n",
       "           cross = TRUE\n",
       "        )\n",
       "     \n",
       "     # ---------------------------------------------------------------------------\n",
       "     \n",
       "     chi_features_res_new <-\n",
       "        chi_features_set %>%\n",
       "        option_add(param_info = pca_param, id = \"plus_pca_lm\") %>%\n",
       "        workflow_map(resamples = time_val_split, grid = 21, seed = 1, verbose = TRUE)\n",
       "     \n",
       "     chi_features_res_new\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO tmp info grounds\n",
    "?workflow_map\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
